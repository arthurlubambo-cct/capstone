{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8854c2-14aa-48b2-84a3-0cf07fcc8450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install visual_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee65f63-d92f-487e-b026-d6f32c8714a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mir_eval.sonify\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd73aa-b2dd-4ca2-9416-fbc01e29d7b8",
   "metadata": {},
   "source": [
    "## Read Queries and Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f1d57-7016-4222-96f9-ed9a7a58df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_df = pd.read_pickle(\"./queries_with_midi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb596f4-1d8e-4d15-9188-f171add6f967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93a270-ba79-4602-8434-1cac134b0559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_df = pd.read_pickle(\"./songs_with_midi.pkl\")\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ea531-feda-43f9-bc44-877ebe50794f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_df[\"voice_piano_roll\"] = songs_df[\"vocals_midi\"].apply(lambda x:x.get_piano_roll(fs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec6999-fbeb-4586-ad81-80f26cfa3afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_df[\"piano_roll\"] = queries_df[\"query_basic_midi\"].apply(lambda x:x.get_piano_roll(fs=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba49fb-3b15-4c18-a40e-062b86d1bdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c58bd-d428-4077-94ba-8aa4373a484d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_test_df = queries_df.sample(frac=0.6)\n",
    "query_train_df = queries_df[~queries_df.index.isin(query_test_df.index)]\n",
    "print(query_test_df.shape)\n",
    "print(query_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb88170-54ba-4060-97fc-3f84c14a1a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_train_df = songs_df[songs_df[\"Song ID\"].isin(query_train_df[\"Song ID\"])]\n",
    "songs_train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d0908-dfe4-4b6f-a199-ccb8ac299fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_test_df = songs_df[~songs_df.index.isin(songs_train_df.index)]\n",
    "songs_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a8bba-8759-4306-a2ef-3d66c241d432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_songs_ids, validation_songs_ids = train_test_split(songs_train_df[\"Song ID\"].tolist(), test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb49d75-c3c9-4abd-b96f-adcb6e030c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_songs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012548df-9091-4747-9b58-a72ee0a5071a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(validation_songs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd496b-e6b4-4cf8-9951-71a822abe48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "def data_aumentation(query_train_df, songs_train_df, songs_ids, factor_increase = 200):\n",
    "    rows = np.array([])\n",
    "    songs_scope_df = songs_train_df[songs_train_df[\"Song ID\"].isin(songs_ids)]\n",
    "    queries_scope_df = query_train_df[query_train_df[\"Song ID\"].isin(songs_ids)]\n",
    "    for song_id in songs_ids:\n",
    "        for i in range(factor_increase):\n",
    "            query_variant = get_random_variation_query_piano_roll(queries_scope_df, song_id)\n",
    "            song_variant = get_random_variation_song_piano_roll(songs_scope_df, song_id)\n",
    "            if(np.random.rand()>.5):\n",
    "                rows = np.append(rows, [query_variant, song_variant, 1.0], axis=0)\n",
    "            else:\n",
    "                rows = np.append(rows, [song_variant, query_variant, 1.0], axis=0)\n",
    "            \n",
    "            neg_song_id = None\n",
    "            while neg_song_id == None or neg_song_id == song_id:\n",
    "                neg_song_id = random.choice(songs_ids)\n",
    "            query_variant = get_random_variation_query_piano_roll(queries_scope_df, song_id)\n",
    "            neg_song_variant = get_random_variation_song_piano_roll(songs_scope_df, neg_song_id)\n",
    "            if(np.random.rand()>.5):\n",
    "                rows = np.append(rows, [neg_song_variant, query_variant, 0.0], axis=0)\n",
    "            else:\n",
    "                rows = np.append(rows, [query_variant, neg_song_variant, 0.0], axis=0)\n",
    "    return np.asarray(rows)\n",
    "            \n",
    "def get_random_variation_song_piano_roll(songs_scope_df,song_id):\n",
    "    song_row = songs_scope_df[songs_scope_df[\"Song ID\"] == song_id].sample(1).iloc[0]\n",
    "    piano_roll = song_row[\"voice_piano_roll\"]\n",
    "    return create_random_variant_piano_roll(piano_roll)\n",
    "    \n",
    "def get_random_variation_query_piano_roll(queries_scope_df,song_id):\n",
    "    query_row = queries_scope_df[queries_scope_df[\"Song ID\"] == song_id].sample(1).iloc[0]\n",
    "    piano_roll = query_row[\"piano_roll\"]\n",
    "    return create_random_variant_piano_roll(piano_roll)\n",
    "\n",
    "def create_random_variant_piano_roll(pr):\n",
    "    return add_noise_to_notes(add_random_silence(random_pitch_roll(pr)))\n",
    "\n",
    "def random_pitch_roll(piano_roll):\n",
    "    return piano_roll\n",
    "    random_shift = random.choice(range(-12,12))\n",
    "    return np.roll(piano_roll, shift=random_shift, axis=0)\n",
    "\n",
    "def add_random_silence(piano_roll):\n",
    "    return piano_roll\n",
    "    pos = random.randint(0,piano_roll.shape[1])\n",
    "    silent_size = random.randint(0,50)\n",
    "    silent = np.zeros((128, silent_size))\n",
    "    return np.concatenate((piano_roll[:,:pos],silent,piano_roll[:,pos:]), axis=1)\n",
    "\n",
    "def add_noise_to_notes(pr):\n",
    "    return piano_roll\n",
    "    def noiser(t):\n",
    "        if(t>0):\n",
    "            return t+np.random.normal(0, 5)\n",
    "        return t\n",
    "    vfunc = np.vectorize(noiser)\n",
    "    return np.asarray(vfunc(pr),dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ce98b-189e-4019-81b0-4dc668fc3d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = data_aumentation(query_train_df, songs_train_df, train_songs_ids, factor_increase = 200)\n",
    "val_data = data_aumentation(query_train_df, songs_train_df, validation_songs_ids, factor_increase = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6faed90-abcd-4b5f-b162-70d0a411fb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408ae85-7409-48c2-b9a9-072e463a080e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0ee9b-5973-4204-9cc2-74aac5b9e710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense, Dot, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def shared_model(input_shape):\n",
    "    model_input = Input(shape=input_shape)\n",
    "    conv_output = Conv1D(filters=64, kernel_size=3, activation='relu')(model_input)\n",
    "    pool_output = MaxPooling1D(pool_size=2)(conv_output)\n",
    "    global_avg_output = GlobalAveragePooling1D()(pool_output)\n",
    "    dense_output = Dense(20, activation='relu')(global_avg_output)\n",
    "    return Model(inputs=model_input, outputs=dense_output)\n",
    "\n",
    "# Input layer 1\n",
    "input_1 = Input(shape=(128, None))\n",
    "shared_output_1 = shared_model((128, None))(input_1)\n",
    "\n",
    "# Input layer 2\n",
    "input_2 = Input(shape=(128, None))\n",
    "shared_output_2 = shared_model((128, None))(input_2)\n",
    "\n",
    "# Compute cosine similarity\n",
    "dot_product = Dot(axes=-1, normalize=True)([shared_output_1, shared_output_2])\n",
    "\n",
    "# Compute cosine similarity with size normalization\n",
    "cosine_similarity = Lambda(lambda x: x[0] / (K.sqrt(K.sum(K.square(x[1]), axis=-1) * K.sum(K.square(x[2]), axis=-1)) + K.epsilon()))([dot_product, shared_output_1, shared_output_2])\n",
    "\n",
    "# Concatenate the original outputs and cosine similarity\n",
    "output = Concatenate()([shared_output_1, shared_output_2, cosine_similarity])\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# Compile and train the model\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1659aba-3ef6-468d-bd89-028d4b2f242a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.rand()>.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8f32e-a901-4ab3-9a9b-c45dd9463573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3911f9-3f07-4ecc-87d5-4bde8ee1006d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='mse',\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a716eb-0021-4c27-a94a-6becc10adc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff95d2-148e-43ae-977b-29974acf712c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c309e-34ef-459c-923e-60d2ef7e579b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08abe348-f04a-45e7-b75f-541d9cb3aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30dcfa3-51b2-47ec-8e2d-4abd948518dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f0ed1-ede4-4d81-afb5-a5102d31561b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d666e-00c6-415e-8cb2-6fab7992f2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "midi = songs_df[\"vocals_midi\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6a109-9fe3-4524-9b36-17b377768321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(midi.get_piano_roll(fs=3)[:,330]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49911d1c-e5b5-4336-919f-0cc662f92bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_midi_piano_roll(array_2d):\n",
    "    array_2d = np.flip(array_2d, axis=0)\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Create a heatmap\n",
    "    sns.heatmap(array_2d, cmap='viridis', cbar_kws={'label': 'Values'})\n",
    "\n",
    "    # Customize labels and title\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Rows')\n",
    "    plt.title('2D Array Heatmap')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    query_midi_wav = midi.synthesize()\n",
    "    display(Audio(data=query_midi_wav, rate=44100))\n",
    "    \n",
    "song_row = songs_df[songs_df[\"Song ID\"] == 1118].iloc[0]\n",
    "# print(song_row)\n",
    "plot_midi_piano_roll(song_row[\"vocals_midi\"].get_piano_roll(fs=3))\n",
    "# query_row = queries_df[queries_df[\"Query ID\"] == 'q1'].iloc[0]\n",
    "# plot_midi_piano_roll(query_row[\"query_basic_midi\"])\n",
    "# print(query_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6c790-0575-45bb-a24a-e148ecced14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_midi_wav = midi.synthesize()\n",
    "display(Audio(data=query_midi_wav, rate=44100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273bdc4-2d86-434d-8548-ee7ff19366e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f4990-320e-4558-a3cb-e8d000286d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66086f-0cbc-4dcd-ae53-93e703939344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6624b788-06d6-4a8f-9b15-c55f55e4c2a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Append Features in Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4bdef-f4fd-4e21-8edb-638f7865a985",
   "metadata": {},
   "source": [
    "#### Metrics Based in OnSet Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550a7d5-507e-47b9-b2a7-175be488d535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522246e8-ec96-4c21-8328-3dba727985b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GET NOTES METRICS BASED ON ONSET DETECT\n",
    "def compute_metrics(audio_file):\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    times = librosa.onset.onset_detect(y=y, sr=sr, units='time')\n",
    "    diff_list = []\n",
    "    for  index, t in enumerate(times):\n",
    "        if(index >0):\n",
    "            diff_list.append(t- times[index-1])\n",
    "    ratio_list = []\n",
    "    for index, t in enumerate(diff_list):\n",
    "        if(index >0):\n",
    "            ratio_list.append(t/diff_list[index-1])\n",
    "    \n",
    "    def clean_ratio_list(raw_list):\n",
    "        def closest(lst, K):\n",
    "            lst = np.asarray(lst)\n",
    "            idx = (np.abs(lst - K)).argmin()\n",
    "            return lst[idx]\n",
    "\n",
    "        times_proportions = [1,0.5,0.333,0.25,2,0.666,3, 1.5, 0.75, 4,1.333]\n",
    "        \n",
    "        result = []\n",
    "        for index, elem in enumerate(raw_list):\n",
    "            if(elem>4):\n",
    "                result.append(str(round(elem)))\n",
    "            else:\n",
    "                result.append(str(closest(times_proportions,elem)))\n",
    "        return result        \n",
    "    return clean_ratio_list(ratio_list)\n",
    "\n",
    "def get_query_metric(row):\n",
    "    return compute_metrics(f\"MTG-QBH/audio/{row['Query ID']}.wav\")\n",
    "\n",
    "def get_ngram_from_list(input_list, n):\n",
    "    n_grams = ngrams(input_list, n)\n",
    "    return [' '.join(grams) for grams in n_grams]      \n",
    "def get_vocal_metric(row):\n",
    "    return compute_metrics(f\"output/htdemucs/{row['Song ID']}/vocals.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ee261-3211-4427-b1a9-c4c3e3ea5e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_df[\"metric\"] = queries_df.apply(lambda row: get_query_metric(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a5204-a732-40ac-8c75-7950fac7f2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_df[\"vocals_metric\"] = songs_df.apply(lambda row: get_vocal_metric(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825dbab0-f133-4c3e-9926-143754b4fc1b",
   "metadata": {},
   "source": [
    "#### Onset Midi Melody Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc02f8-8550-4c69-b07c-42c3b296b378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_inside_beat(note, start, end):\n",
    "    if(start <= note.start and note.start<= end):\n",
    "        return True\n",
    "    if(start <= note.end and note.end<= end):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_notes_between(notes, start, end):\n",
    "    return list(filter(lambda x: is_inside_beat(x, start, end), notes))\n",
    "def get_longest_inside_beat(notes, start, end):\n",
    "    candidates = get_notes_between(notes, start, end)\n",
    "    if(len(candidates)>0):\n",
    "        max_duration = 0\n",
    "        selected = None\n",
    "        for cand in candidates:\n",
    "            dur = min(end, cand.end) - max(start,cand.start)\n",
    "            if(max_duration < dur):\n",
    "                max_duration = dur\n",
    "                selected = cand        \n",
    "        if(selected is not None):\n",
    "            note = copy.deepcopy(selected)\n",
    "            note.start = start\n",
    "            note.end = start+max_duration\n",
    "            return note\n",
    "    return None\n",
    "\n",
    "def get_all_notes_from(midi):\n",
    "    notes= []\n",
    "    for inst in midi.instruments:\n",
    "        notes = notes + inst.notes\n",
    "    return notes\n",
    "    \n",
    "def clean_midi_based_onset(y, sr, midi):\n",
    "    times = librosa.onset.onset_detect(y=y, sr=sr, units='time')\n",
    "    all_notes = get_all_notes_from(midi)\n",
    "    result_notes = []\n",
    "    for index, t in enumerate(times):\n",
    "        if(index< len(times)-1):\n",
    "            note = get_longest_inside_beat(all_notes, t, times[index+1])\n",
    "            if(note is not None):\n",
    "                result_notes.append(note)\n",
    "                \n",
    "    copy_midi = copy.deepcopy(midi)\n",
    "    copy_midi.instruments[0].notes = result_notes\n",
    "    return copy_midi\n",
    "def compute_on_set_melody(audio_path, midi):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    return clean_midi_based_onset(y,sr, midi)\n",
    "\n",
    "def get_query_clean_midi(row):\n",
    "    midi = row['query_basic_midi']\n",
    "    return compute_on_set_melody(f\"MTG-QBH/audio/{row['Query ID']}.wav\", midi )\n",
    "\n",
    "queries_df[\"clean_midi_onset\"] = queries_df.apply(lambda r: get_query_clean_midi(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57770be-8443-4019-9ad3-74e88576fe38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_song_clean_midi(row):\n",
    "    midi = row['vocals_midi']\n",
    "    return compute_on_set_melody(f\"output/htdemucs/{row['Song ID']}/vocals.wav\", midi)\n",
    "\n",
    "songs_df[\"vocal_clean_midi\"] = songs_df.apply(lambda r: get_song_clean_midi(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c96b6-8527-4e69-b429-45a81766eb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a937b36-edb6-4b54-900f-188dabb0b232",
   "metadata": {},
   "source": [
    "### On Beat Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15722e3-c644-4e93-86f8-4aca1902d1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import bisect\n",
    "\n",
    "class ClosestKeyDict:\n",
    "    def __init__(self, list_pair):\n",
    "        self._dict = collections.OrderedDict(list_pair)\n",
    "        self.keys = list(self._dict.keys())\n",
    "    def get_first_pos_greater(self, v):\n",
    "        pos = bisect.bisect_left(list(self._dict.keys()), v)\n",
    "        return pos\n",
    "    def get_closest_key(self, key_in):\n",
    "        pos = self.get_first_pos_greater(key_in)\n",
    "        key = self.keys[pos]\n",
    "        if(pos>0):\n",
    "            key_before = self.keys[pos-1]\n",
    "            if(abs(key_in-key_before) < abs(key-key_in)):\n",
    "                return key_before\n",
    "        return key\n",
    "    def get_closest_value_from_key(self, key_in, threshold = float('inf')):\n",
    "        key = self.get_closest_key(key_in)\n",
    "        if(abs(key-search_key)<threshold):\n",
    "            return self._dict[key]\n",
    "        return None\n",
    "        \n",
    "def build_frequencies_dict(f0, voiced_flag):\n",
    "    times = librosa.times_like(f0)\n",
    "    pairs = []\n",
    "    for index, f in enumerate(f0):\n",
    "        if(voiced_flag[index]):\n",
    "            pairs.append((times[index], f))\n",
    "        else:\n",
    "            pairs.append((times[index], None))\n",
    "    return ClosestKeyDict(pairs)\n",
    "\n",
    "def get_audio_signature_transcription(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    display(Audio(data=y,rate=sr))\n",
    "    \n",
    "    tempo, beats = get_beats(y, sr)\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'),fmax=librosa.note_to_hz('C7'), frame_length=1024)\n",
    "    f0_dict = build_frequencies_dict(f0,voiced_flag)\n",
    "    trans_1 = get_melody_transcription(f0_dict,tempo, beats, level=1) \n",
    "    display_transcript(trans_1, beats, sr)\n",
    "    trans_2 = get_melody_transcription(f0_dict,tempo, beats, level=2)\n",
    "    display_transcript(trans_2, beats, sr)\n",
    "    return [trans_1, trans_2]\n",
    "\n",
    "def display_transcript(transcripts, beats, sr):\n",
    "    freq = np.array(list(map(lambda x: librosa.midi_to_hz(x) if x is not None else None , transcripts)))\n",
    "    mask = np.array(list(map(lambda x: True if x is not None else False , freq)))\n",
    "    # beats_masked = np.ma.MaskedArray(beats, mask=~mask).compressed()\n",
    "    times= librosa.times_like(freq, sr=sr)\n",
    "    beats_masked = np.ma.MaskedArray(times, mask=~mask).compressed()\n",
    "    freq_masked = np.ma.MaskedArray(freq, mask=~mask).compressed()\n",
    "\n",
    "    y = mir_eval.sonify.pitch_contour(beats_masked, freq_masked, sr)\n",
    "    display(Audio(data=y, rate=sr))\n",
    "def get_melody_transcription(f0_dict, tempo, beats, level = 1):\n",
    "    result = []\n",
    "    threshold = tempo/(level*2)\n",
    "    for index, beat in enumerate(beats):\n",
    "        freq = f0_dict.get_closest_value_from_key(beat,threshold)\n",
    "        note = None\n",
    "        if(freq is not None):\n",
    "            note = round(librosa.hz_to_midi(freq))\n",
    "        result.append(note)\n",
    "    return result\n",
    "    \n",
    "def get_subdivision_beats(beats:np.array, num:int):\n",
    "    result = []\n",
    "    for ind, beat in enumerate(beats):\n",
    "        result.append(beat)\n",
    "        next_beat = None\n",
    "        if(ind+1<len(beats)):\n",
    "            next_beat = beats[ind+1]\n",
    "        if(next_beat is not None):\n",
    "            diff = next_beat-beat\n",
    "            step = diff/num\n",
    "            for index in range(1,num):\n",
    "                sub_beat = beat+step*index\n",
    "                result.append(sub_beat)\n",
    "    return result\n",
    "                \n",
    "def get_beats(y, sr):\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    beats_time = librosa.frames_to_time(beats)\n",
    "    return tempo, beats_time\n",
    "\n",
    "\n",
    "def plot_transcription(data):\n",
    "    # Create lists to store the positions and heights of bars\n",
    "    bar_positions = []\n",
    "    bar_heights = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for i, value in enumerate(data):        \n",
    "        bar_positions.append(i)\n",
    "        if(value is None):\n",
    "            bar_heights.append(0.0)\n",
    "        else:\n",
    "            bar_heights.append(value)\n",
    "\n",
    "    sns.barplot(x=bar_positions, y=bar_heights, color=\"blue\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "trans_1, trans_2 = get_audio_signature_transcription(f\"MTG-QBH/audio/q27.wav\")\n",
    "print(trans_1)\n",
    "plot_transcription(trans_1)\n",
    "print(trans_2)\n",
    "plot_transcription(trans_2)\n",
    "\n",
    "trans_song_1, trans_song_2 = get_audio_signature_transcription(f\"output/htdemucs/789/vocals.wav\")\n",
    "print(trans_song_1)\n",
    "plot_transcription(trans_song_1)\n",
    "print(trans_song_2)\n",
    "plot_transcription(trans_song_2)\n",
    "# sub_beats = get_subdivision_beats(beats, 2)\n",
    "# for ind, beat in enumerate(beats):\n",
    "#     if(ind+1 < len(beats)):\n",
    "#         print(f\"{beats[ind+1]-beats[ind]}\")\n",
    "\n",
    "# for ind, beat in enumerate(sub_beats):\n",
    "#     if(ind+1 < len(sub_beats)):\n",
    "#         print(f\"{sub_beats[ind+1]-sub_beats[ind]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a07b81-b755-4764-ba9f-7bfd79d8b0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a1bd2-5232-4fef-bfa2-7a65a26b90de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e16735-fcd5-4bb8-9a6b-f222278eac50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_n_gram_from_notes(notes, n):\n",
    "    result = []\n",
    "    l = len(notes)\n",
    "    for idx, note in enumerate(notes):\n",
    "        if(idx+1<l-1):\n",
    "            diff = notes[idx+1].pitch - note.pitch\n",
    "            diff = str(diff)\n",
    "            result.append(diff)\n",
    "    n_grams = ngrams(result, n)\n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def get_midi_n_grams(midi, n):\n",
    "    result = []\n",
    "    for inst in midi.instruments:\n",
    "        if(not inst.is_drum):\n",
    "            n_grams = get_n_gram_from_notes(inst.notes,n)\n",
    "            result = result+n_grams\n",
    "    return result\n",
    "\n",
    "def get_n_grams(midi):\n",
    "    grams = get_midi_n_grams(midi,3)\n",
    "    return grams\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376c203-01d6-4f50-8fe9-6c70efe48912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_df[\"query_n_grams\"] = queries_df[\"query_basic_midi\"].apply(get_n_grams)\n",
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e7d97-ede0-4b6a-9dc5-149dd37ced77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Size Sets for Queries\n",
    "queries_df[\"query_n_grams\"].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15e59c-d67d-461f-b508-72d7120b5fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songs_df[\"song_n_grams\"] = songs_df[\"vocals_midi\"].apply(get_n_grams)\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb9700-e650-4533-b373-feafe24cd813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Size Sets for Songs\n",
    "songs_df[\"song_n_grams\"].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8dc005-223d-44b6-8d6f-93ab3e9b1e01",
   "metadata": {},
   "source": [
    "## Calculate Similarity Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a5a70-f038-4461-931c-be8c70e8df0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_overlap_coef(a,b):\n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    inter_set = a_set.intersection(b_set)\n",
    "    return len(inter_set)/min(len(a_set),len(b_set))\n",
    "\n",
    "def get_index_of_song_in_query(cross_df, query_id,song_id):\n",
    "    query_results = cross_df[cross_df[\"Query ID\"] == query_id]\n",
    "    list_results = query_results[\"Song ID\"].tolist()\n",
    "    if(song_id in list_results):\n",
    "        return list_results.index(song_id)+1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def inverse(num):\n",
    "    return 1.0/num\n",
    "\n",
    "def get_mrr(rank_list):\n",
    "    result = {}\n",
    "    ranks = rank_list[np.logical_not(np.isnan(rank_list))]\n",
    "    inverted_ranks = inverse(ranks)\n",
    "    result[\"mrr\"] = inverted_ranks.mean()\n",
    "    result[\"count\"] = len(inverted_ranks)\n",
    "    return result\n",
    "def run_experiment(queries_df, songs_df,queries_set_col, songs_set_col):\n",
    "    q_df = queries_df.copy()\n",
    "    s_df = songs_df.copy()\n",
    "    cross_df = q_df[[\"Query ID\",queries_set_col]].merge(s_df[[\"Song ID\",songs_set_col]], how=\"cross\")\n",
    "    cross_df[\"similarity\"] = cross_df.apply(lambda row: get_overlap_coef(row[queries_set_col], row[songs_set_col]), axis=1)\n",
    "    cross_df = cross_df.sort_values(by=\"similarity\", ascending=False)\n",
    "    q_df[\"index_search\"] = q_df.apply(lambda x: get_index_of_song_in_query(cross_df, x[\"Query ID\"], x[\"Song ID\"]) , axis=1)\n",
    "    \n",
    "    q_df.sort_values(by=\"index_search\")\n",
    "    result = get_mrr(q_df[\"index_search\"])\n",
    "    result[\"mean_song_set_size\"] = s_df[songs_set_col].apply(lambda x: len(x)).mean()\n",
    "    result[\"mean_query_set_size\"] = q_df[queries_set_col].apply(lambda x: len(x)).mean()\n",
    "    result[\"index_search_mean\"] = q_df[\"index_search\"].mean()\n",
    "    return result, q_df, cross_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1897af-62cd-48a1-bae1-0131a1b7ae47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment_metric(queries_df, songs_df, from_n, to_n):\n",
    "    def get_multi_grams(set_list, from_n = 3, to_n=5):\n",
    "        result = []\n",
    "        for i in range(from_n, to_n+1):\n",
    "            result = result + get_ngram_from_list(set_list,i)\n",
    "        return result\n",
    "    q_df = queries_df.copy()\n",
    "    s_df = songs_df.copy()\n",
    "    q_df[\"query_metric_set\"] = q_df[\"metric\"].apply(lambda x: get_multi_grams(x, from_n, to_n))\n",
    "    s_df[\"song_metric_set\"] = s_df[\"vocals_metric\"].apply(lambda x: get_multi_grams(x, from_n, to_n))\n",
    "    \n",
    "    return run_experiment(q_df, s_df,\"query_metric_set\",\"song_metric_set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60653113-fd0b-490f-8cc0-2cb3ee4a7b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,2,2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5f72b-a802-493a-a473-a9cf08f93d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,3,3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bb045-840c-4dff-97c9-06306a96e547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,4,4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8441b58-9de2-4fea-ab40-7faee83b3a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,5,5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547cd33-c21e-44e3-bd84-cbf910bab7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,6,6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1397518-223c-4375-8e60-5671d541fa85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,7,7)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109597d-b0e1-4a6d-9a1a-3f126dfa76b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, _, cr_sim = run_experiment_metric(queries_df, songs_df,4,6)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfe7eb-ccf9-45aa-83f9-5c4b521b890a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr_sim[\"similarity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce1a5e-fd74-4bc8-97c0-93366de73001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_metric(queries_df, songs_df,5,6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5ee6b-00a7-4e52-9866-157f37995dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment_midi(queries_df, songs_df,midi_to_gram = None,):\n",
    "    q_df = queries_df.copy()\n",
    "    s_df = songs_df.copy()\n",
    "    q_df[\"query_n_grams\"] = q_df[\"query_basic_midi\"].apply(midi_to_gram)\n",
    "    s_df[\"song_n_grams\"] = s_df[\"vocals_midi\"].apply(midi_to_gram)\n",
    "   \n",
    "    return run_experiment(q_df, s_df,\"query_n_grams\",\"song_n_grams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5ed7f-a35a-4bd6-9a5b-2548543dc596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aea681-fed2-4014-ad36-36f723b215b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,4))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f776eb-368c-4e31-ba07-e70fa6f08dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,5))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292bd44a-8ab9-472f-91fe-bb299b94487b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,6))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44065c66-daec-4206-9b47-bfb646d7bf07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,7))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76ba10-fb02-41f2-a36c-aec944ae3765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,8))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02edb543-dbde-4c4b-a8c8-777260031eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,9))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d6c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_midi_n_grams(midi,14))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d720b34-f4e2-486c-b2e4-9a9bdfd7bb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_multi_grams(query_midi, from_n = 3, to_n=5):\n",
    "    result = []\n",
    "    for i in range(from_n, to_n+1):\n",
    "        result = result + get_midi_n_grams(query_midi,i)\n",
    "    return result\n",
    "\n",
    "run_experiment_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,4,9))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491cfa1-6707-421c-a5c7-5e0b6a9547d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,4,14))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd69cb-aac5-4a89-be78-9fad6ef90242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_experiment_clean_midi(queries_df, songs_df,midi_to_gram = None,):\n",
    "    q_df = queries_df.copy()\n",
    "    s_df = songs_df.copy()\n",
    "    q_df[\"query_n_grams\"] = q_df[\"clean_midi_onset\"].apply(midi_to_gram)\n",
    "    s_df[\"song_n_grams\"] = s_df[\"vocal_clean_midi\"].apply(midi_to_gram)\n",
    "   \n",
    "    return run_experiment(q_df, s_df,\"query_n_grams\",\"song_n_grams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed73b-2160-4dac-bcd6-9690e420abd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,3,3))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69745228-8230-4f68-9a75-86afb48934da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,4,4))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817dbfbf-f85c-44d0-a6ec-d334209924bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,5,5))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336e2cc-5a6c-4c6f-b65b-684fa38562bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,6,6))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d865bb5-7a74-497f-9b47-8f93095e2439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,7,7))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0eb99-bf5f-4ced-8b0e-46bf381c19bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,3,8))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44635ef-7e8b-4dc5-904d-5232ba6b2cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, q_df, _ = run_experiment_clean_midi(queries_df, songs_df, lambda midi: get_multi_grams(midi,4,6))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1889b6-2a0e-4f98-9926-d97e77a4d8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(q_df[\"index_search\"]<=10).sum()/(q_df[\"index_search\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbdce1-5acf-4edc-b5ec-71ac629d7549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_df[\"index_search\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3260c71-90d8-43c7-b64c-8ff8399410e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_df[q_df[\"index_search\"]>300].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564d4c0-05a9-422c-bcfd-169704ce88b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1d3bf-1c8c-4d7d-9e9d-df39cbea3193",
   "metadata": {},
   "source": [
    "### EDA Exploring Query Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3080ce-d8ee-45b1-bbd9-2ebf3f6bc5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "def plot_midi(midi):\n",
    "    notes = list(map(lambda note: (note.start,note.pitch,note.end-note.start), midi.instruments[0].notes))\n",
    "    # Sample data\n",
    "    x = [t[0] for t in notes]\n",
    "    y = [t[1] for t in notes]\n",
    "    z = [t[2] for t in notes]\n",
    "    \n",
    "    output_notebook()\n",
    "    \n",
    "    # Create a ColumnDataSource with the data\n",
    "    source = ColumnDataSource(data=dict(time=x, pitch=y, duration=z))\n",
    "\n",
    "    # Create a Bokeh figure\n",
    "    p = figure(width=400, height=400, title=\"Scatter Plot with Rectangles\")\n",
    "\n",
    "    # Add rectangles to the plot\n",
    "    p.rect(x='time', y='pitch', width='duration', height=1, source=source, fill_alpha=0, line_color='black')\n",
    "\n",
    "    # Set axis labels\n",
    "    p.xaxis.axis_label = 'Time'\n",
    "    p.yaxis.axis_label = 'Pitch'\n",
    "\n",
    "    # Show the plot\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58916564-46c5-4bef-bcec-9944aa4cab29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383ede4-2de2-4be4-8320-3916facbc9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def does_overlap(noteA, noteB):\n",
    "    if(noteA.start <= noteB.start and noteB.start<= noteA.end):\n",
    "        return True\n",
    "    if(noteB.start <= noteA.start and noteA.start<= noteB.end):\n",
    "        return True\n",
    "    if(noteA.start <= noteB.end and noteB.end<= noteA.end):\n",
    "        return True\n",
    "    if(noteB.start <= noteA.end and noteA.end<= noteB.end):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def clean_midi(midi_in):\n",
    "    midi = copy.deepcopy(midi_in)\n",
    "    inst_index = 0\n",
    "    for instrument in midi.instruments:\n",
    "        clean_notes = []\n",
    "        for note in instrument.notes:\n",
    "            clean_notes.append(note)\n",
    "            intersection = list(filter(lambda x:does_overlap(note, x),  clean_notes))\n",
    "            if(len(intersection)==0):\n",
    "                clean_notes.append(note)\n",
    "            else:\n",
    "                pass\n",
    "#                 velocities = list(map(lambda x: x.velocity, intersection))\n",
    "#                 index_max = np.argmax(velocities)\n",
    "                \n",
    "#                 clean_notes.append(intersection[index_max])\n",
    "\n",
    "        # clean_notes = sorted(list(set(clean_notes)), key=lambda x: x.start)\n",
    "        \n",
    "        result = []\n",
    "        median_duration = np.median(list(map(lambda x: x.end-x.start, clean_notes)))\n",
    "        print(f\"MEDIAN:{median_duration}\")\n",
    "        for index, note in enumerate(clean_notes):\n",
    "            is_note_clean = True\n",
    "            if(index > 0):\n",
    "                if(clean_notes[index-1].pitch == note.pitch):\n",
    "                    is_note_clean = False\n",
    "            current_duration = note.end - note.start\n",
    "            if(median_duration/current_duration > 8):\n",
    "                is_note_clean = False\n",
    "            if(is_note_clean):\n",
    "                result.append(note)\n",
    "            \n",
    "        instrument.notes = result\n",
    "        midi.instruments[inst_index] = instrument\n",
    "        inst_index +=1 \n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d633c77-8e7b-4787-978f-8352190c4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f0_time_notes(y, sr):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bc2f9-c5bc-4d06-9882-d0d20f80d90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyse_query_song(query_id, song_id, midi_to_gram):\n",
    "    q_y, sr = librosa.load(f\"MTG-QBH/audio/{query_id}.wav\")\n",
    "    display(Audio(data=q_y, rate=sr))\n",
    "    \n",
    "    query_data = queries_df[queries_df[\"Query ID\"] == query_id].iloc[0]\n",
    "    query_midi = query_data[\"query_basic_midi\"]\n",
    "    plot_midi(query_midi)\n",
    "    query_midi_wav = query_midi.synthesize()\n",
    "    display(Audio(data=query_midi_wav, rate=44100))\n",
    "    \n",
    "    s_y, sr = librosa.load(f\"songs_wav/{song_id}.wav\")\n",
    "    display(Audio(data=s_y, rate=sr))\n",
    "    \n",
    "    s_vocals_y, sr = librosa.load(f\"output/htdemucs/{song_id}/vocals.wav\")\n",
    "    display(Audio(data=s_vocals_y, rate=sr))\n",
    "    \n",
    "    song_data = songs_df[songs_df[\"Song ID\"] == int(song_id)].iloc[0]\n",
    "    song_vocals_midi = song_data[\"vocals_midi\"]\n",
    "    plot_midi(song_vocals_midi)\n",
    "    song_vocals_midi_wav = song_vocals_midi.synthesize()\n",
    "    display(Audio(data=song_vocals_midi_wav, rate=44100))\n",
    "    \n",
    "\n",
    "    query_set = midi_to_gram(query_midi)\n",
    "    song_set = midi_to_gram(song_vocals_midi)\n",
    "    similarity = get_overlap_coef(query_set, song_set)\n",
    "    \n",
    "    display(f\"Similarity:{similarity}\")\n",
    "    \n",
    "    clean_query_midi = clean_midi_based_onset(q_y,sr, query_midi)\n",
    "    plot_midi(clean_query_midi)\n",
    "    clean_query_midi_wav = clean_query_midi.synthesize()\n",
    "    display(Audio(data=clean_query_midi_wav, rate=44100))\n",
    "    query_set = midi_to_gram(clean_query_midi)\n",
    "    \n",
    "    \n",
    "    clean_song_midi = clean_midi_based_onset(s_vocals_y,sr,song_vocals_midi)\n",
    "    plot_midi(clean_song_midi)\n",
    "    clean_song_midi_wav = clean_song_midi.synthesize()\n",
    "    display(Audio(data=clean_song_midi_wav, rate=44100))\n",
    "    song_set = midi_to_gram(clean_song_midi)\n",
    "#     clean_query_midi = clean_midi(query_midi)\n",
    "#     plot_midi(clean_query_midi)\n",
    "#     clean_query_midi_wav = clean_query_midi.synthesize()\n",
    "#     display(Audio(data=clean_query_midi_wav, rate=44100))\n",
    "#     query_set = midi_to_gram(clean_query_midi)\n",
    "    \n",
    "    \n",
    "#     clean_song_midi = clean_midi(song_vocals_midi)\n",
    "#     plot_midi(clean_song_midi)\n",
    "#     clean_song_midi_wav = clean_song_midi.synthesize()\n",
    "#     display(Audio(data=clean_song_midi_wav, rate=44100))\n",
    "#     song_set = midi_to_gram(clean_song_midi)\n",
    "    \n",
    "    clean_similarity = get_overlap_coef(query_set, song_set)\n",
    "    \n",
    "    display(f\"Similarity Clean :{clean_similarity}\")\n",
    "    \n",
    "    query_metric = get_metric_list(q_y, sr)\n",
    "    vocals_metric = get_metric_list(s_vocals_y, sr)\n",
    "        \n",
    "    query_gram = get_ngram_from_list(query_metric,4)\n",
    "    vocals_gram = get_ngram_from_list(vocals_metric,4)\n",
    "    \n",
    "    metric_similarity = get_overlap_coef(query_gram, vocals_gram)\n",
    "    \n",
    "    display(f\"Metric Similarity:{metric_similarity}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return metric_similarity\n",
    "analyse_query_song(\"q59\",\"1396\",   lambda midi: get_multi_grams(midi,4,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28d941-e85c-4183-8141-fdae9523819d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(librosa.ex('trumpet'))\n",
    "display(Audio(data=y, rate=sr))\n",
    "librosa.onset.onset_detect(y=y, sr=sr, units='time')\n",
    "o_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "times = librosa.times_like(o_env, sr=sr)\n",
    "onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)\n",
    "onset_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b48ea7-ad49-49c7-97fb-3d3c0905ca60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1608222-3eb6-440d-b50d-d7495ab663db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a76da-e743-4cc1-8d0a-ecb8f597fb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3aa9a-2210-46c2-8b5f-df18b8725435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "D = np.abs(librosa.stft(y))\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),\n",
    "                         x_axis='time', y_axis='log', ax=ax[0])\n",
    "ax[0].set(title='Power spectrogram')\n",
    "ax[0].label_outer()\n",
    "ax[1].plot(times, o_env, label='Onset strength')\n",
    "ax[1].vlines(times[onset_frames], 0, o_env.max(), color='r', alpha=0.9,\n",
    "           linestyle='--', label='Onsets')\n",
    "ax[1].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473f578-2945-4b34-9ea4-4756abb2edac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from visual_midi import Plotter\n",
    "from visual_midi import Preset\n",
    "from pretty_midi import PrettyMIDI\n",
    "\n",
    "preset = Preset(plot_width=850)\n",
    "plotter = Plotter(preset, plot_max_length_bar=4)\n",
    "plotter.plot(midi)\n",
    "_ColorGroupMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f152c2-e752-4b98-9e16-1ce1580bebe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79684a-dcc0-4dd2-9787-e97a0c01e7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63677436-7ff8-400e-b808-c1abc0d71121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed0eda-cdeb-4bae-9f4e-d00d3ebbe182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0399b2b-4577-4e7c-a817-bba4d1fbac72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT\n",
    "# y, sr = librosa.load(librosa.ex('choice'))\n",
    "def shift_audio(query_filename, steps = 4):\n",
    "    y, sr = librosa.load(f\"MTG-QBH/audio/{query_filename}\")\n",
    "    y_third = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "    y_strech = librosa.effects.time_stretch(y,  rate=0.8)\n",
    "    display(Audio(data=y, rate=sr))\n",
    "    display(Audio(data=y_third, rate=sr))\n",
    "    display(Audio(data= y_strech, rate=sr))\n",
    "shift_audio(\"q3.wav\",4)\n",
    "\n",
    "# shift_audio(\"q3.wav\",2)\n",
    "# shift_audio(\"q3.wav\",-12)\n",
    "# shift_audio(\"q3.wav\",12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3575ab-3f9b-45e3-8692-68cc6ae70867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# y, sr = librosa.load(librosa.ex('choice'))\n",
    "y, sr = librosa.load(f\"MTG-QBH/audio/q3.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b769c0-251a-4d5b-b367-d88fded2498e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, beat_frames = librosa.beat.beat_track(y=y, sr=sr,\n",
    "                                         hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ed005-3080-4002-8085-c953b1ad8c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beat_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efc2dd-430e-43f3-b327-438e4d614e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beat_samples = librosa.frames_to_samples(beat_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1459251-39a4-47f1-8fd6-130134c2a3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beat_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ab97c-68df-4d8f-bfaf-1a9877afd0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intervals = librosa.util.frame(beat_samples, frame_length=2, hop_length=1).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa458cc-f9d4-4599-a890-327b43ea403d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1adbd-e8cf-4952-bc8e-f293ddb39a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_out = librosa.effects.remix(y, intervals[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5568b31-cae5-463e-97bc-74a403d3b180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Audio(data= y, rate=sr))\n",
    "display(Audio(data= y_out, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23feb13e-0541-4c49-9d8b-09abc8d4ae3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
